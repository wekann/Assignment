{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzkoNZZMX2JYzEiTLUSqB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wekann/Assignment/blob/main/Neural_Network_A_Simples_Perception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Q1. What is Deep Learning and how is it connected to Artificial Intelligence?\n",
        "Definition of Deep Learning:\n",
        "\n",
        "Deep Learning is a subset of Machine Learning, which itself is a branch of Artificial Intelligence (AI). Deep learning uses neural networks with many layers (hence “deep”) to learn patterns and representations from large amounts of data.\n",
        "Connection to Artificial Intelligence:\n",
        "\n",
        "| Concept                          | Description                                                                                                              |\n",
        "| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |\n",
        "| Artificial Intelligence (AI)     | Broad field focused on building machines that can mimic human intelligence — e.g., decision making, reasoning, learning. |\n",
        "| Machine Learning (ML)            | A subfield of AI where systems learn from data without being explicitly programmed.                                      |\n",
        "| Deep Learning (DL)               | A subfield of ML that uses **deep neural networks** to automatically extract features and make predictions.              |\n",
        "\n",
        "So, deep learning is a tool used to achieve AI.\n",
        "Example Hierarchy:\n",
        "\n",
        "```\n",
        "Artificial Intelligence\n",
        "│\n",
        "├── Machine Learning\n",
        "│   └── Algorithms: Decision Trees, SVMs, k-NN, etc.\n",
        "│\n",
        "└── Deep Learning\n",
        "    └── Neural Networks: CNNs, RNNs, Transformers, etc.\n",
        "```\n",
        "Why Deep Learning Matters in AI:\n",
        "\n",
        "* High accuracy on complex tasks: vision, speech, NLP.\n",
        "* Learns features automatically (no manual feature engineering).\n",
        "* Powers AI applications like:\n",
        "\n",
        "  * Self-driving cars\n",
        "  * Chatbots (like ChatGPT)\n",
        "  * Face recognition\n",
        "  * Language translation"
      ],
      "metadata": {
        "id": "P5q20sshTWFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q2. What is neural network, and what are the different types of Neural Networks?\n",
        "What is a Neural Network?\n",
        "\n",
        "A Neural Network is a computational model inspired by the human brain that is designed to recognize patterns and relationships in data. It consists of layers of interconnected neurons (or nodes), where each neuron processes input and passes the output to the next layer.\n",
        "\n",
        "Each connection has a weight, and each neuron has an activation function that determines its output.\n",
        "Basic Structure of a Neural Network:\n",
        "\n",
        "* Input Layer: Receives the input data\n",
        "* Hidden Layers: Perform computations and feature extraction\n",
        "* Output Layer: Produces the final result or prediction\n",
        "\n",
        "How It Works (Forward Propagation):\n",
        "1. Inputs are fed to the input layer.\n",
        "2. Each neuron computes a weighted sum of inputs and applies an activation function.\n",
        "3. The result is passed to the next layer.\n",
        "4. This continues until the output layer produces the result.\n",
        "\n",
        "Types of Neural Networks:\n",
        "\n",
        "| Type                                        | Description                                                      | Common Use Cases                       |\n",
        "| ------------------------------------------- | ---------------------------------------------------------------- | -------------------------------------- |\n",
        "| 1. Feedforward Neural Network (FNN)         | Basic architecture where data flows one way from input to output | Classification, regression             |\n",
        "| 2. Convolutional Neural Network (CNN)       | Uses convolution layers to process spatial data                  | Image recognition, video analysis      |\n",
        "| 3. Recurrent Neural Network (RNN)           | Has loops to process sequential data                             | Time series, speech, text              |\n",
        "| 4. Long Short-Term Memory (LSTM)            | A type of RNN that solves vanishing gradient problems            | Language modeling, machine translation |\n",
        "| 5. Gated Recurrent Unit (GRU)               | A simplified LSTM, faster to train                               | Sequence data with limited memory      |\n",
        "| 6. Autoencoder                              | Learns efficient data encoding/decoding                          | Anomaly detection, compression         |\n",
        "| 7. Generative Adversarial Network (GAN)     | Consists of a generator and discriminator in a game              | Image generation, deepfakes            |\n",
        "| 8. Radial Basis Function Network (RBFN)     | Uses radial basis functions as activation                        | Function approximation                 |\n",
        "| 9. Transformer Networks                     | Uses attention mechanism for handling sequences                  | NLP (e.g., ChatGPT, BERT)              |\n",
        "\n",
        "Visualization (Simple):\n",
        "\n",
        "```\n",
        "Input → [Hidden Layer 1] → [Hidden Layer 2] → Output\n",
        "```\n",
        "\n",
        "In CNN:\n",
        "\n",
        "```\n",
        "Image → [Convolution + Pooling] → [Dense Layers] → Output"
      ],
      "metadata": {
        "id": "E-8YfGbGTV6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q3. What is the mathematical structure of a neural network?\n",
        "A neural network can be described mathematically as a composition of linear algebra operations (like matrix multiplication) followed by non-linear activation functions, organized in layers.\n",
        "1.Basic Structure (One Neuron)\n",
        "A single neuron performs the following computation:\n",
        "\n",
        "$$\n",
        "z = w^T x + b\n",
        "$$\n",
        "\n",
        "$$\n",
        "a = \\phi(z)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $x \\in \\mathbb{R}^n$ is the input vector\n",
        "* $w \\in \\mathbb{R}^n$ is the weight vector\n",
        "* $b \\in \\mathbb{R}$ is the bias term\n",
        "* $\\phi$ is an activation function (like ReLU, sigmoid)\n",
        "* $a$ is the neuron's output\n",
        "\n",
        "2. Layer-wise Computation\n",
        "\n",
        "For a layer with multiple neurons:\n",
        "\n",
        "$$\n",
        "Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}\n",
        "$$\n",
        "\n",
        "$$\n",
        "A^{[l]} = \\phi(Z^{[l]})\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $l$ = layer index\n",
        "* $A^{[0]} = X$ is the input\n",
        "* $W^{[l]}$ = weight matrix of shape $(n_l, n_{l-1})$\n",
        "* $b^{[l]}$ = bias vector of shape $(n_l, 1)$\n",
        "* $Z^{[l]}$ = pre-activation vector\n",
        "* $A^{[l]}$ = output (activation) of the layer\n",
        "\n",
        "3. Forward Propagation\n",
        "\n",
        "Given input $X$, the network computes:\n",
        "\n",
        "$$\n",
        "A^{[1]} = \\phi(W^{[1]} X + b^{[1]})\n",
        "$$\n",
        "\n",
        "$$\n",
        "A^{[2]} = \\phi(W^{[2]} A^{[1]} + b^{[2]})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cdots\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{Y} = A^{[L]} = \\phi(W^{[L]} A^{[L-1]} + b^{[L]})\n",
        "$$\n",
        "\n",
        "Where $L$ is the total number of layers and $\\hat{Y}$ is the output.\n",
        "\n",
        "4. Loss Function\n",
        "\n",
        "To train the network, define a loss function $\\mathcal{L}(\\hat{Y}, Y)$ to measure the error between predicted and actual outputs.\n",
        "\n",
        "Common examples:\n",
        "\n",
        "* MSE for regression:\n",
        "\n",
        "  $$\n",
        "  \\mathcal{L} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})^2\n",
        "  $$\n",
        "* Binary Crossentropy for classification:\n",
        "\n",
        "  $$\n",
        "  \\mathcal{L} = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]\n",
        "  $$\n",
        "\n",
        "5. Backpropagation (Gradient Descent)\n",
        "\n",
        "Weights are updated using derivatives of the loss with respect to each parameter:\n",
        "\n",
        "$$\n",
        "W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial W^{[l]}}\n",
        "$$\n",
        "\n",
        "Where $\\alpha$ is the learning rate."
      ],
      "metadata": {
        "id": "r27ZGx0wTV4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q4. What isan activation function,  and why is it essential in neural\n",
        "What is an Activation Function?\n",
        "\n",
        "An activation function is a mathematical function applied to the output of a neuron after computing the weighted sum of its inputs. It introduces non-linearity into the neural network.\n",
        "Mathematically:\n",
        "\n",
        "$$\n",
        "a = \\phi(z), \\quad \\text{where } z = w^T x + b\n",
        "$$\n",
        "\n",
        "* $\\phi$ = activation function\n",
        "* $z$ = linear combination of inputs\n",
        "* $a$ = output after activation\n",
        "\n",
        "Why is it Essential?\n",
        "\n",
        "1. Introduces Non-Linearity\n",
        "\n",
        "   * Without activation functions, the neural network would be just a linear model, no matter how many layers you add.\n",
        "   * Non-linearity allows networks to **learn complex patterns.\n",
        "\n",
        "2. Enables Deep Learning\n",
        "\n",
        "   * Activation functions make it possible to stack multiple layers and learn hierarchical features.\n",
        "\n",
        "3. Helps in Feature Transformation\n",
        "\n",
        "   * It maps input features to a range that makes learning more efficient (e.g., between 0 and 1, or -1 and 1).\n",
        "\n",
        "Common Activation Functions:\n",
        "\n",
        "| Function       | Formula                             | Output Range | Use Case                     |\n",
        "| -------------- | ----------------------------------- | ------------ | ---------------------------- |\n",
        "| Sigmoid        | $\\frac{1}{1 + e^{-z}}$              | (0, 1)       | Binary classification        |\n",
        "| Tanh           | $\\frac{e^z - e^{-z}}{e^z + e^{-z}}$ | (−1, 1)      | Hidden layers in RNNs        |\n",
        "| ReLU           | $\\max(0, z)$                        | \\[0, ∞)      | Most common in hidden layers |\n",
        "| Leaky ReLU     | $\\max(0.01z, z)$                    | (−∞, ∞)      | Fixes dying ReLU problem     |\n",
        "| Softmax        | $\\frac{e^{z_i}}{\\sum_j e^{z_j}}$    | (0, 1)       | Output layer for multi-class |\n",
        "\n",
        "Example:\n",
        "\n",
        "Suppose a neuron calculates $z = 1.2$\n",
        "\n",
        "* Without activation: output = 1.2 (linear)\n",
        "* With ReLU: output = 1.2\n",
        "* With Sigmoid: output ≈ 0.768\n",
        "* With Tanh: output ≈ 0.833"
      ],
      "metadata": {
        "id": "b1KqJCJtTV1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q5. Could you list some common activation functions used in neural networks?\n",
        "Here are the most commonly used activation functions, along with their characteristics, formulas, and typical use cases:\n",
        "1. Sigmoid (Logistic)\n",
        "\n",
        "$$\n",
        "\\phi(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "* Output Range: (0, 1)\n",
        "* Pros: Good for binary classification.\n",
        "* Cons: Vanishing gradient problem, slow convergence.\n",
        "\n",
        "Use in: Output layer for binary classification.\n",
        "\n",
        "2. Tanh (Hyperbolic Tangent)\n",
        "\n",
        "$$\n",
        "\\phi(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n",
        "$$\n",
        "\n",
        "* Output Range: (−1, 1)\n",
        "* Pros: Zero-centered output (better than sigmoid).\n",
        "* Cons: Still suffers from vanishing gradients.\n",
        "\n",
        "Use in: Hidden layers, especially in RNNs.\n",
        "\n",
        "3. ReLU (Rectified Linear Unit)\n",
        "\n",
        "$$\n",
        "\\phi(z) = \\max(0, z)\n",
        "$$\n",
        "\n",
        "* Output Range: \\[0, ∞)\n",
        "* Pros: Fast training, sparse activation.\n",
        "* Cons: \"Dying ReLU\" problem (some neurons become inactive).\n",
        "\n",
        "Use in: Hidden layers in CNNs, DNNs.\n",
        "\n",
        "4. Leaky ReLU\n",
        "\n",
        "$$\n",
        "\\phi(z) = \\begin{cases}\n",
        "z & \\text{if } z > 0 \\\\\n",
        "\\alpha z & \\text{if } z \\leq 0\n",
        "\\end{cases}\n",
        "\\quad \\text{(typically } \\alpha = 0.01\\text{)}\n",
        "$$\n",
        "\n",
        "Fixes ReLU by allowing a small gradient when $z \\leq 0$.\n",
        "\n",
        "Use in: Deep neural networks to avoid dead neurons.\n",
        "\n",
        "5. Parametric ReLU (PReLU)\n",
        "\n",
        "Similar to Leaky ReLU, but $\\alpha$ is learned during training.\n",
        "\n",
        "Use in: Custom or advanced networks needing more flexibility.\n",
        "\n",
        "6. ELU (Exponential Linear Unit)\n",
        "\n",
        "$$\n",
        "\\phi(z) = \\begin{cases}\n",
        "z & \\text{if } z > 0 \\\\\n",
        "\\alpha (e^z - 1) & \\text{if } z \\leq 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Smoother output than ReLU, avoids zero gradient.\n",
        "\n",
        "Use in: Deep models where ReLU struggles.\n",
        "\n",
        "7. Softmax\n",
        "\n",
        "$$\n",
        "\\phi(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
        "$$\n",
        "\n",
        "* Output Range: (0, 1), all values sum to 1.\n",
        "* Converts logits into probability distribution.\n",
        "\n",
        "Use in: Output layer of multi-class classification models.\n",
        "\n",
        "Summary Table:\n",
        "\n",
        "| Activation | Range   | Use Case                            |\n",
        "| ---------- | ------- | ----------------------------------- |\n",
        "| Sigmoid    | (0, 1)  | Binary classification (output)      |\n",
        "| Tanh       | (−1, 1) | RNNs, hidden layers                 |\n",
        "| ReLU       | \\[0, ∞) | Hidden layers (CNNs, MLPs)          |\n",
        "| Leaky ReLU | (−∞, ∞) | Avoid dying neurons in deep nets    |\n",
        "| PReLU      | (−∞, ∞) | Learnable variant of Leaky ReLU     |\n",
        "| ELU        | (−α, ∞) | Smooth version of ReLU              |\n",
        "| Softmax    | (0, 1)  | Multi-class classification (output) |"
      ],
      "metadata": {
        "id": "FhIHwQPCTVzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q6. What is a multilayer neural network?\n",
        "\n",
        "Definition:\n",
        "A Multilayer Neural Network (also known as a Multilayer Perceptron or MLP) is a type of feedforward artificial neural network that contains one or more hidden layers between the input and output layers.\n",
        "\n",
        "These layers enable the model to learn complex, non-linear relationships in data.\n",
        "Structure of a Multilayer Neural Network:\n",
        "\n",
        "1. Input Layer\n",
        "\n",
        "   * Receives the raw data (features).\n",
        "\n",
        "2. Hidden Layers\n",
        "\n",
        "   * One or more layers that process inputs using weights, biases, and activation functions.\n",
        "   * These layers extract features and learn representations.\n",
        "\n",
        "3. Output Layer\n",
        "\n",
        "   * Produces the final prediction or classification.\n",
        "\n",
        "Mathematical Representation:\n",
        "For layer $l$:\n",
        "\n",
        "$$\n",
        "Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}\n",
        "$$\n",
        "\n",
        "$$\n",
        "A^{[l]} = \\phi(Z^{[l]})\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $A^{[0]}$ = Input\n",
        "* $W^{[l]}$, $b^{[l]}$ = Weights and biases\n",
        "* $\\phi$ = Activation function\n",
        "* $A^{[l]}$ = Output (activation) of layer $l$\n",
        "\n",
        "Visualization:\n",
        "\n",
        "```\n",
        "Input → [Hidden Layer 1] → [Hidden Layer 2] → ... → Output\n",
        "```\n",
        "\n",
        "Each arrow represents weighted connections with an activation function.\n",
        "\n",
        "Key Characteristics:\n",
        "\n",
        "* Deep learning starts when a neural network has multiple hidden layers.\n",
        "* Backpropagation is used to train the network by minimizing the loss.\n",
        "* Multilayer networks can approximate any continuous function (Universal Approximation Theorem).\n",
        "\n",
        "Applications:\n",
        "\n",
        "* Classification (e.g., spam detection, image recognition)\n",
        "* Regression (e.g., predicting house prices)\n",
        "* Time series forecasting\n",
        "* Pattern recognition and NLP (with added architectures)"
      ],
      "metadata": {
        "id": "fuvgzJtRTVOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q7. What is a loss function, and why is it crucial for neural network training?\n",
        "What is a Loss Function?\n",
        "\n",
        "A loss function (also called a cost function or objective function) is a mathematical function that measures the difference between the predicted output of a neural network and the actual target value (ground truth).\n",
        "\n",
        "It quantifies how wrong the model's prediction is.\n",
        "\n",
        "Mathematical Form:\n",
        "For a single training example:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\hat{y}, y)\n",
        "$$\n",
        "\n",
        "* $\\hat{y}$ = predicted output\n",
        "* $y$ = actual output\n",
        "* $\\mathcal{L}$ = loss value (scalar)\n",
        "\n",
        "For all training examples (m samples):\n",
        "\n",
        "$$\n",
        "\\text{Total Loss} = \\frac{1}{m} \\sum_{i=1}^{m} \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)})\n",
        "$$\n",
        "\n",
        "Why is it Crucial?\n",
        "\n",
        "1. Guides Learning:\n",
        "\n",
        "   * The loss function tells the model how well it is performing.\n",
        "   * Training algorithms (like gradient descent) use the loss to adjust weights** in the network.\n",
        "\n",
        "2. Objective for Optimization:\n",
        "\n",
        "   * The goal of training is to minimize the loss.\n",
        "   * The lower the loss, the better the model is performing on the task.\n",
        "\n",
        "3. Backpropagation Depends on It:\n",
        "\n",
        "   * Loss values are used to compute gradients that flow backward through the network during training.\n",
        "\n",
        "Common Loss Functions:\n",
        "\n",
        "| Loss Function                 | Formula                                    | Use Case                           |   |                                 |\n",
        "| ----------------------------- | ------------------------------------------ | ---------------------------------- | - | ------------------------------- |\n",
        "| Mean Squared Error (MSE)      | $\\frac{1}{m} \\sum (y - \\hat{y})^2$         | Regression problems                |   |                                 |\n",
        "| Mean Absolute Error (MAE)     | ( \\frac{1}{m} \\sum                         | y - \\hat{y}                        | ) | Regression (robust to outliers) |\n",
        "| Binary Crossentropy           | $-[y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})]$ | Binary classification              |   |                                 |\n",
        "| Categorical Crossentropy      | $-\\sum y_i \\log(\\hat{y}_i)$                | Multi-class classification         |   |                                 |\n",
        "| Hinge Loss                    | $\\max(0, 1 - y\\hat{y})$                    | SVM-like classification            |   |                                 |\n",
        "| Huber Loss                    | Mix of MSE and MAE                         | Regression with outlier robustness |   |                                 |\n"
      ],
      "metadata": {
        "id": "dDLv6HPuVkNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q8. What are some common type of loss function?\n",
        "Loss functions differ depending on the type of task: regression, binary classification, or multi-class classification.\n",
        "1. Regression Loss Functions\n",
        "\n",
        "Used when the output is continuous (e.g., predicting price, temperature).\n",
        "\n",
        "| Loss Function                 | Formula                                | Description                                       |   |                                                     |\n",
        "| ----------------------------- | -------------------------------------- | ------------------------------------------------- | - | --------------------------------------------------- |\n",
        "| Mean Squared Error (MSE)      | $\\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2$ | Penalizes large errors more (quadratic loss).     |   |                                                     |\n",
        "| Mean Absolute Error (MAE)     | ( \\frac{1}{n} \\sum                     | y\\_i - \\hat{y}\\_i                                 | ) | Treats all errors equally; more robust to outliers. |\n",
        "| Huber Loss                    | Combines MSE and MAE for robustness.   | Smooth for small errors, MAE-like for large ones. |   |                                                     |\n",
        "| Log-Cosh Loss                 | $\\sum \\log(\\cosh(\\hat{y}_i - y_i))$    | Less sensitive to outliers than MSE.              |   |                                                     |\n",
        "\n",
        "2. Classification Loss Functions\n",
        "\n",
        "Used for discrete outputs, such as class labels.\n",
        "\n",
        "a) Binary Classification (2 classes):\n",
        "\n",
        "| Loss Function           | Formula                                        | Description                                                   |\n",
        "| ----------------------- | ---------------------------------------------- | ------------------------------------------------------------- |\n",
        "| **Binary Crossentropy** | $-[y\\log(\\hat{y}) + (1 - y)\\log(1 - \\hat{y})]$ | Measures difference between predicted prob. and actual class. |\n",
        "\n",
        "b) Multi-Class Classification:\n",
        "\n",
        "| Loss Function                                   | Formula                                                  | Description                                                      |\n",
        "| ----------------------------------------------- | -------------------------------------------------------- | ---------------------------------------------------------------- |\n",
        "| Categorical Crossentropy                        | $-\\sum y_i \\log(\\hat{y}_i)$                              | Use when labels are one-hot encoded.                             |\n",
        "| Sparse Categorical Crossentropy                 | Similar to above, but labels are integers (not one-hot). | Use when labels are not one-hot encoded.                         |\n",
        "| Kullback-Leibler Divergence (KL Divergence)     | $\\sum y_i \\log\\left(\\frac{y_i}{\\hat{y}_i}\\right)$        | Measures how one probability distribution diverges from another. |\n",
        "\n",
        "3. Other Specialized Losses\n",
        "\n",
        "| Loss Function        | Use Case                                                                  |\n",
        "| -------------------- | ------------------------------------------------------------------------- |\n",
        "| Hinge Loss           | Used in SVMs and \"max-margin\" classifiers.                                |\n",
        "| Contrastive Loss     | Used in Siamese networks and similarity tasks.                            |\n",
        "| Triplet Loss         | Used in face recognition and embedding tasks.                             |\n",
        "| Dice Loss            | Used in image segmentation (especially medical imaging).                  |\n",
        "| Focal Loss           | Used for imbalanced classification problems (e.g., rare class detection). |\n",
        "\n",
        "Summary Table\n",
        "\n",
        "| Task                  | Loss Function                   |\n",
        "| --------------------- | ------------------------------- |\n",
        "| Regression            | MSE, MAE, Huber, Log-Cosh       |\n",
        "| Binary Classification | Binary Crossentropy             |\n",
        "| Multi-Class           | Categorical/Sparse Crossentropy |\n",
        "| Probabilistic Models  | KL Divergence                   |\n",
        "| Similarity/Ranking    | Contrastive, Triplet, Hinge     |\n",
        "| Image Segmentation    | Dice, Focal                     |"
      ],
      "metadata": {
        "id": "ANkJ7-kGVj8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q9. How does a neural network learn?\n",
        "A neural network learns by adjusting its weights and biases to minimize the loss (error between predicted output and actual output) through a process called training.\n",
        "The Learning Process (Step-by-Step):\n",
        "\n",
        "1. Forward Propagation\n",
        "* The input data is passed through the network layer by layer.\n",
        "* Each neuron computes a weighted sum and applies an **activation function**.\n",
        "* The final output $\\hat{y}$ is generated.\n",
        "\n",
        "$$\n",
        "z = w^T x + b,\\quad a = \\phi(z)\n",
        "$$\n",
        "\n",
        "2. Loss Calculation\n",
        "\n",
        "* The output $\\hat{y}$ is compared with the true label $y$.\n",
        "* A **loss function** computes the error.\n",
        "\n",
        "$$\n",
        "\\text{Loss} = \\mathcal{L}(\\hat{y}, y)\n",
        "$$\n",
        "\n",
        "3. Backpropagation\n",
        "\n",
        "* The network computes gradients of the loss with respect to each weight using chain rule (automatic differentiation).\n",
        "* This determines how much each weight contributed to the error.\n",
        "\n",
        "4. Weight Update (Gradient Descent)\n",
        "\n",
        "* Weights are updated in the opposite direction of the gradient to minimize the loss.\n",
        "\n",
        "$$\n",
        "w := w - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial w}\n",
        "$$\n",
        "\n",
        "* $\\eta$ = learning rate (controls step size)\n",
        "* Repeat this process for all weights and biases.\n",
        "\n",
        "Repeated Over Epochs:\n",
        "\n",
        "* One full pass over the dataset = 1 epoch.\n",
        "* Network iteratively reduces error and improves predictions.\n",
        "\n",
        "Example Summary:\n",
        "\n",
        "| Step                 | What Happens                             |\n",
        "| -------------------- | ---------------------------------------- |\n",
        "| Forward Pass         | Compute outputs from inputs              |\n",
        "| Loss Computation     | Measure how wrong predictions are        |\n",
        "| Backpropagation      | Compute gradients of loss w\\.r.t weights |\n",
        "| Weight Update        | Update weights to reduce loss            |\n",
        "\n",
        "Optimization Techniques:\n",
        "\n",
        "* Optimizers: SGD, Adam, RMSProp\n",
        "* Regularization: Dropout, L2 penalty\n",
        "* Normalization: Batch normalization\n",
        "* Data Handling: Batching, shuffling\n"
      ],
      "metadata": {
        "id": "SGS8tWPVVj5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q10. What is an optimizer in neural Networks, and why is it necessary?\n",
        "\n",
        "What Is an Optimizer?\n",
        "An optimizer is an algorithm used to adjust the weights and biases of a neural network during training to minimize the loss function.\n",
        "\n",
        "In simple terms:\n",
        "The optimizer helps the network learn faster and better by deciding how to update the model's parameters.\n",
        "\n",
        "Why Is It Necessary?\n",
        "* Neural networks learn by reducing the error (loss).\n",
        "* To do that, they must tweak their internal parameters (weights).\n",
        "* The optimizer guides this update process using gradients computed through backpropagation.\n",
        "\n",
        "Without an optimizer:\n",
        "The network cannot improve — it will never learn from its mistakes.\n",
        "\n",
        "How It Works:\n",
        "1. Compute gradients of the loss w\\.r.t. weights:\n",
        "\n",
        "   $$\n",
        "   \\frac{\\partial \\text{Loss}}{\\partial w}\n",
        "   $$\n",
        "\n",
        "2. Update the weights using an optimizer-specific rule:\n",
        "\n",
        "   $$\n",
        "   w := w - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial w}\n",
        "   $$\n",
        "\n",
        "   Where $\\eta$ is the learning rate.\n",
        "\n",
        "Common Optimizers in Deep Learning:\n",
        "\n",
        "| Optimizer                             | Description                                               |\n",
        "| ------------------------------------- | --------------------------------------------------------- |\n",
        "| SGD (Stochastic Gradient Descent)     | Basic, updates weights for each training example.         |\n",
        "| SGD with Momentum                     | Adds momentum to avoid local minima and oscillations.     |\n",
        "| RMSProp                               | Scales learning rate based on recent gradient magnitudes. |\n",
        "| Adam (Adaptive Moment Estimation)     | Combines momentum + RMSProp. Most commonly used today.    |\n",
        "| Adagrad                               | Adjusts learning rate for each parameter individually.    |\n",
        "| Adadelta                              | An improvement over Adagrad.                              |\n",
        "\n",
        "Example (Adam in Keras):\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "'''"
      ],
      "metadata": {
        "id": "Czqq1ghSVj2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q11. Could you briefly describe some common optimizers?\n",
        "Optimizers help improve a neural network's performance by minimizing the loss function through weight updates. Below are some of the most widely used optimizers, each with unique characteristics:\n",
        "\n",
        "1. SGD (Stochastic Gradient Descent)\n",
        "* Description:Updates weights using gradients from each mini-batch of data.\n",
        "* Formula:\n",
        "\n",
        "  $$\n",
        "  w := w - \\eta \\cdot \\nabla L\n",
        "  $$\n",
        "* Pros:Simple and effective.\n",
        "* Cons:Slow convergence; can get stuck in local minima.\n",
        "* Use Case:Works well with convex problems or large datasets.\n",
        "\n",
        "2. SGD with Momentum\n",
        "* Description:Adds a velocity term to remember the previous update direction, helping to smooth and speed up convergence.\n",
        "* Formula:\n",
        "\n",
        "  $$\n",
        "  v := \\gamma v + \\eta \\nabla L,\\quad w := w - v\n",
        "  $$\n",
        "* Pros:Reduces oscillations, accelerates convergence.\n",
        "* Use Case:Useful in deep networks and sparse gradients.\n",
        "\n",
        "3. RMSProp (Root Mean Square Propagation)\n",
        "* Description:Scales the learning rate for each parameter based on the moving average of squared gradients.\n",
        "* Formula:\n",
        "\n",
        "  $$\n",
        "  E[g^2]_t = \\beta E[g^2]_{t-1} + (1 - \\beta)g_t^2\n",
        "  $$\n",
        "\n",
        "  $$\n",
        "  w := w - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} \\cdot g_t\n",
        "  $$\n",
        "* Pros: Handles non-stationary objectives well.\n",
        "* Use Case:Recommended for RNNs and time series problems.\n",
        "\n",
        "4. Adam (Adaptive Moment Estimation)\n",
        "\n",
        "* Description: Combines the advantages of Momentum and RMSProp. Maintains running averages of both gradients and squared gradients.\n",
        "* Formula:\n",
        "\n",
        "  * $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t$\n",
        "  * $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2$\n",
        "  * Bias correction + weight update\n",
        "* Pros:Fast convergence, low memory usage, good default choice.\n",
        "* Use Case: Works well in most deep learning applications.\n",
        "\n",
        "5. Adagrad (Adaptive Gradient)\n",
        "* Description:Adapts learning rate to parameters, performing larger updates for infrequent parameters.\n",
        "* Cons:Learning rate decreases too much over time.\n",
        "* Use Case:Sparse data problems like NLP or recommender systems.\n",
        "\n",
        "6. Adadelta\n",
        "* Description:Improvement over Adagrad that limits aggressive decay in learning rate.\n",
        "* Pros:Better for longer training periods.\n",
        "* Use Case:Similar to Adagrad but better generalization.\n",
        "\n",
        "Summary Table\n",
        "\n",
        "| Optimizer    | Highlights                          | Best For                        |\n",
        "| ------------ | ----------------------------------- | ------------------------------- |\n",
        "| SGD          | Simple, slow but steady             | Large datasets, basic tasks     |\n",
        "| Momentum     | Faster convergence                  | Deep networks                   |\n",
        "| RMSProp      | Adaptive learning rate              | RNNs, non-stationary data       |\n",
        "| Adam         | Most popular, fast + adaptive       | General-purpose deep learning   |\n",
        "| Adagrad      | Good for sparse data                | Text/NLP, sparse feature spaces |\n",
        "| Adadelta     | Fixes Adagrad’s learning rate decay | Longer training runs            |"
      ],
      "metadata": {
        "id": "crhX-c2dVj0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q12. Can you explain forward and backward propagation?\n",
        "Forward and Backward Propagation are the two main phases in training a neural network.\n",
        "\n",
        "They work together to compute predictions, evaluate errors, and adjust weights so the network learns over time.\n",
        "1. Forward Propagation (Prediction Phase)\n",
        "\n",
        "> Data moves forward through the network — from input to output — to generate a prediction.\n",
        "Steps:\n",
        "\n",
        "1. Input:Feed the input vector $x$ to the network.\n",
        "2. Linear Transformation:\n",
        "\n",
        "   $$\n",
        "   z = w^T x + b\n",
        "   $$\n",
        "3. Activation:Apply activation function $a = \\phi(z)$ (e.g., ReLU, sigmoid).\n",
        "4. Repeat for all hidden layers.\n",
        "5. Output:Get final prediction $\\hat{y}$.\n",
        "6. Loss:Compare $\\hat{y}$ to actual label $y$ using a loss function $\\mathcal{L}(\\hat{y}, y)$.\n",
        "\n",
        "2. Backward Propagation (Learning Phase)\n",
        "> Error is propagated backward from output to input to update weights using gradients.\n",
        "\n",
        "Goal:\n",
        "Minimize the loss $\\mathcal{L}$ by adjusting the weights and biases using gradient descent.\n",
        "\n",
        "Steps:\n",
        "1. Compute Gradients:\n",
        "   Use                                                                                                                                                                                                         chain rule to calculate how the loss changes with respect to each parameter:\n",
        "\n",
        "   $$\n",
        "   \\frac{\\partial \\mathcal{L}}{\\partial w}\n",
        "   $$\n",
        "\n",
        "2. Update Weights:\n",
        "   Using gradient descent:\n",
        "\n",
        "   $$\n",
        "   w := w - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial w}\n",
        "   $$\n",
        "\n",
        "   * $\\eta$ = learning rate\n",
        "\n",
        "3. Repeat the process for each layer backward (from output to input).\n",
        "\n",
        "Example:\n",
        "\n",
        "For one hidden layer neural network:\n",
        "\n",
        "* Forward:\n",
        "\n",
        "  * $z_1 = W_1x + b_1$\n",
        "  * $a_1 = \\text{ReLU}(z_1)$\n",
        "  * $z_2 = W_2a_1 + b_2$\n",
        "  * $\\hat{y} = \\text{Softmax}(z_2)$\n",
        "\n",
        "* Backward:\n",
        "\n",
        "  * Compute $\\frac{\\partial \\mathcal{L}}{\\partial W_2}, \\frac{\\partial \\mathcal{L}}{\\partial W_1}$\n",
        "  * Update weights with optimizer\n",
        "\n",
        "Process Overview Diagram:\n",
        "\n",
        "Input → [Layer 1] → [Layer 2] → ... → Output (ŷ)\n",
        "   ↓                             ↑\n",
        "Forward Propagation         Backward Propagation\n",
        "```\n",
        "Summary:\n",
        "\n",
        "| Phase             | Purpose                           | Direction      |\n",
        "| ----------------- | --------------------------------- | -------------- |\n",
        "| Forward Pass      | Predict output, compute loss      | Input → Output |\n",
        "| Backward Pass     | Compute gradients, update weights | Output → Input |\n"
      ],
      "metadata": {
        "id": "cEe848HWVjnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q13. what is weight initialization, and how does it impact training?\n",
        "### ✅ Q13. What Is Weight Initialization, and How Does It Impact Training in Neural Networks?\n",
        "\n",
        "What Is Weight Initialization?\n",
        "Weight initialization refers to the process of setting the initial values of the weights (and sometimes biases) of a neural network before training begins.\n",
        "\n",
        "Why Is It Important?\n",
        "\n",
        "Neural networks learn by adjusting weights, so their initial values can greatly affect:\n",
        "\n",
        "* Training speed\n",
        "* Convergence to a good solution\n",
        "* Avoidance of vanishing or exploding gradients\n",
        "* Model accuracy\n",
        "\n",
        "Bad initialization = slow or failed learning\n",
        "Good initialization = faster, stable convergence\n",
        "\n",
        "Common Weight Initialization Methods\n",
        "\n",
        "| Method                             | Description                                                       |\n",
        "| ---------------------------------- | ----------------------------------------------------------------- |\n",
        "| Zero Initialization                | All weights = 0. Not recommended (symmetry problem).              |\n",
        "| Random Initialization              | Random small values (helps break symmetry).                       |\n",
        "| Xavier (Glorot) Initialization     | For tanh or sigmoid activations. Balances variance across layers. |\n",
        "| He Initialization                  | For ReLU or variants. Deals with variance better in deep nets.    |\n",
        "| LeCun Initialization               | Good for SELU activation.                                         |\n",
        "\n",
        "1. Xavier (Glorot) Initialization\n",
        "\n",
        "* Designed to keep the variance of activations and gradients the same across layers.\n",
        "* Formula:\n",
        "\n",
        "  $$\n",
        "  W \\sim \\mathcal{U} \\left(-\\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}} \\right)\n",
        "  $$\n",
        "* Best for: Sigmoid, Tanh\n",
        "\n",
        "2. He Initialization\n",
        "\n",
        "* Focuses on maintaining variance for ReLU-type activations.\n",
        "* Formula:\n",
        "\n",
        "  $$\n",
        "  W \\sim \\mathcal{N}(0, \\frac{2}{n_{in}})\n",
        "  $$\n",
        "* Best for: ReLU, Leaky ReLU\n",
        "Impact on Training\n",
        "\n",
        "| Initialization                | Effect on Training                        |\n",
        "| ----------------------------- | ----------------------------------------- |\n",
        "| Poor (e.g., all 0s)           | No learning, neurons become identical     |\n",
        "| Too large                     | Exploding gradients                       |\n",
        "| Too small                     | Vanishing gradients                       |\n",
        "| Well-chosen (e.g., He/Xavier) | Fast, stable convergence, better accuracy |\n",
        "\n",
        "Keras Example:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.initializers import HeNormal, GlorotUniform\n",
        "\n",
        "# Xavier/Glorot for sigmoid/tanh\n",
        "Dense(64, activation='tanh', kernel_initializer=GlorotUniform())\n",
        "\n",
        "# He for ReLU\n",
        "Dense(64, activation='relu', kernel_initializer=HeNormal())\n",
        "```"
      ],
      "metadata": {
        "id": "4TsNxO4TX-2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q14. what is the vanishing gradient problem in deep learning?\n",
        "Definition:\n",
        "The vanishing gradient problem occurs when the gradients of the loss function become extremely small as they are backpropagated through a deep neural network, especially in very deep architectures.\n",
        "\n",
        "When Does It Happen?\n",
        "During backpropagation, the gradient (partial derivative of the loss) is calculated layer by layer. In very deep networks, these gradients get multiplied many times by small derivative values (especially from activation functions like sigmoid or tanh), causing them to shrink exponentially.\n",
        "\n",
        "What’s the Problem?\n",
        "* Weights in earlier layers update very little (or not at all).\n",
        "* These layers learn very slowly, or stop learning entirely.\n",
        "* The model may get stuck and fail to converge to a good solution.\n",
        "* It leads to poor performance**, especially in deep networks like RNNs or deep CNNs.\n",
        "\n",
        "Mathematical View (Simplified):\n",
        "\n",
        "Each layer:\n",
        "\n",
        "$$\n",
        "a = \\phi(w^T x + b)\n",
        "$$\n",
        "\n",
        "Backpropagation of gradient:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{\\partial \\mathcal{L}}{\\partial a} \\cdot \\frac{\\partial a}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w}\n",
        "$$\n",
        "\n",
        "For sigmoid:\n",
        "\n",
        "$$\n",
        "\\frac{d\\sigma(z)}{dz} = \\sigma(z)(1 - \\sigma(z)) \\in (0, 0.25)\n",
        "$$\n",
        "\n",
        "Multiplying these small values across layers:\n",
        "\n",
        "$$\n",
        "\\text{gradient} \\approx 0\n",
        "$$\n",
        "\n",
        "Example Activation Functions That Cause It:\n",
        "\n",
        "* Sigmoid\n",
        "* Tanh\n",
        "\n",
        "Solutions to Vanishing Gradient:\n",
        "\n",
        "| Solution                           | Description                                   |\n",
        "| ---------------------------------- | --------------------------------------------- |\n",
        "| ReLU Activation                    | Avoids saturation → gradient is 1 for $z > 0$ |\n",
        "| He/Xavier Initialization           | Keeps variance of gradients consistent        |\n",
        "| Batch Normalization                | Normalizes activations → stabilizes gradients |\n",
        "| Residual Connections (ResNets)     | Shortcuts help gradient flow                  |\n",
        "| LSTM/GRU (for RNNs)                | Designed to handle long-term dependencies     |\n"
      ],
      "metadata": {
        "id": "O-i6gTgtX-hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q15. What is the exploding gradient problem?\n",
        "Definition:\n",
        "\n",
        "The exploding gradient problem occurs when the gradients during backpropagation become excessively large, causing unstable training, nan values, or even divergence (model fails to learn).\n",
        "When Does It Happen?\n",
        "In very deep networks or RNNs, backpropagation involves multiplying many gradient terms. If those terms are larger than 1, the gradient can grow exponentially as it moves backward through layers.\n",
        "What’s the Problem?\n",
        "\n",
        "* Weights get huge, leading to:\n",
        "  * Loss becoming `NaN`\n",
        "  * Model diverging\n",
        "  * Training instability\n",
        "* Network may never converge to a solution\n",
        "* Makes training unreliable or unusable\n",
        "\n",
        "Mathematical Intuition:\n",
        "During backpropagation:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial w} = \\prod_{i=1}^L \\frac{\\partial a_i}{\\partial a_{i-1}}\n",
        "$$\n",
        "\n",
        "If each derivative > 1, then:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial w} \\rightarrow \\infty\n",
        "$$\n",
        "\n",
        "Symptoms of Exploding Gradients:\n",
        "\n",
        "* Loss spikes to infinity or NaN\n",
        "* Model accuracy jumps randomly\n",
        "* Weights have abnormally large values\n",
        "* Training crashes or becomes very slow\n",
        "\n",
        "Solutions to Exploding Gradients:\n",
        "\n",
        "| Solution                              | Description                               |\n",
        "| ------------------------------------- | ----------------------------------------- |\n",
        "| Gradient Clipping                     | Caps the gradient to a maximum value      |\n",
        "| Proper Weight Initialization          | Use He/Xavier to stabilize variance       |\n",
        "| Batch Normalization                   | Reduces internal covariate shift          |\n",
        "| Smaller Learning Rate                 | Prevents drastic weight updates           |\n",
        "| Use of Normalized RNNs (LSTM/GRU)     | Handles gradient better than vanilla RNNs |\n",
        "\n",
        "Example: Gradient Clipping in Keras\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Clip gradients to max norm of 1.0\n",
        "optimizer = Adam(clipnorm=1.0)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "```"
      ],
      "metadata": {
        "id": "BULyN79EX-ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRACTICAL QUESTION & ANSWER"
      ],
      "metadata": {
        "id": "_2G73MK3TBZ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkCb_3aJO8hd"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Q1.How do you create a simple perceptron for basic binary classification?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step function (activation)\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Perceptron class\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.bias = 0\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def predict(self, x):\n",
        "        total = np.dot(x, self.weights) + self.bias\n",
        "        return step_function(total)\n",
        "\n",
        "    def train(self, X, y, epochs=10):\n",
        "        for _ in range(epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                pred = self.predict(xi)\n",
        "                error = target - pred\n",
        "                self.weights += self.lr * error * xi\n",
        "                self.bias += self.lr * error\n",
        "\n",
        "# Example usage\n",
        "# Input data (AND gate)\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([0, 0, 0, 1])  # AND output\n",
        "\n",
        "# Train perceptron\n",
        "p = Perceptron(input_size=2)\n",
        "p.train(X, y)\n",
        "\n",
        "# Test\n",
        "print(\"Predictions:\")\n",
        "for xi in X:\n",
        "    print(f\"{xi} => {p.predict(xi)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q2. how can you build a neural network with one hidden layer using keras?\n",
        "To build a neural network with one hidden layer using Keras, follow these simple steps. Keras is a high-level API in TensorFlow that makes building neural networks easy and readable.\n",
        "\n",
        "Step-by-Step Guide: One Hidden Layer Neural Network\n",
        "Step 1: Import Libraries\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "```\n",
        "Step 2: Build the Model\n",
        "\n",
        "```python\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer + Hidden layer (e.g., 8 neurons, ReLU activation)\n",
        "model.add(Dense(8, input_dim=2, activation='relu'))\n",
        "\n",
        "# Output layer (1 neuron for binary classification, sigmoid activation)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "Step 3: Compile the Model\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "Step 4: Train the Model\n",
        "\n",
        "```python\n",
        "# Example data: XOR problem (you can use your dataset)\n",
        "import numpy as np\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([0,1,1,0])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "```\n",
        "Step 5: Evaluate / Predict\n",
        "\n",
        "```python\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X, y)\n",
        "print(f\"Accuracy: {acc:.2f}\")\n",
        "\n",
        "# Predict new values\n",
        "predictions = model.predict(X)\n",
        "print(\"Predictions:\\n\", predictions)\n",
        "```\n",
        "Network Architecture Summary:\n",
        "\n",
        "* Input layer: 2 input neurons (from `input_dim=2`)\n",
        "* Hidden layer: 8 neurons, `ReLU` activation\n",
        "* Output layer: 1 neuron, `sigmoid` activation (for binary classification)"
      ],
      "metadata": {
        "id": "8DFlrSitPK8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q3. How do you initialize weights using the xavier(Glorot) initialization method in keras?\n",
        "To initialize weights using the Xavier (Glorot) initialization method in Keras, you can use:\n",
        "```python\n",
        "kernel_initializer='glorot_uniform'\n",
        "```\n",
        "\n",
        "or\n",
        "\n",
        "```python\n",
        "kernel_initializer='glorot_normal'\n",
        "```\n",
        "\n",
        "---\n",
        "What is Xavier (Glorot) Initialization?\n",
        "\n",
        "Xavier initialization is designed to maintain the variance of activations across layers:\n",
        "\n",
        "* glorot\\_uniform: weights are sampled from a uniform distribution.\n",
        "* glorot\\_normal: weights are sampled from a normal distribution.\n",
        "\n",
        "Both are suitable for activations like `tanh` or `sigmoid`.\n",
        "\n",
        "Example: Using Xavier Initialization in Keras\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Hidden layer with Xavier uniform initialization\n",
        "model.add(Dense(8, input_dim=4, activation='relu', kernel_initializer='glorot_uniform'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
        "```\n",
        "Customizing Further (Optional)\n",
        "\n",
        "If you want to import and use explicitly:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "\n",
        "model.add(Dense(8, input_dim=4, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "```\n",
        "When to Use It:\n",
        "\n",
        "* glorot\\_uniform: Default for most layers in Keras (good for `relu`, `tanh`)\n",
        "* glorot\\_normal: Sometimes better with `sigmoid`"
      ],
      "metadata": {
        "id": "TjC6FVz0PiWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q4. How can you apply different activation function in a neural network in keras?\n",
        " To apply different activation functions in a neural network using Keras, you simply specify the desired activation function using the `activation` parameter in each layer (typically `Dense`, `Conv2D`, etc.).\n",
        "\n",
        "Syntax\n",
        "\n",
        "```python\n",
        "Dense(units, activation='activation_name')\n",
        "```\n",
        "or using functional form:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.activations import relu, sigmoid\n",
        "Dense(units, activation=relu)\n",
        "```\n",
        "Common Activation Functions in Keras\n",
        "\n",
        "| Activation                      | Use Case                                  |\n",
        "| ------------------------------- | ----------------------------------------- |\n",
        "| `'relu'`                        | Most common for hidden layers             |\n",
        "| `'sigmoid'`                     | Binary classification (output layer)      |\n",
        "| `'tanh'`                        | Hidden layers (range: -1 to 1)            |\n",
        "| `'softmax'`                     | Multi-class classification (output layer) |\n",
        "| `'linear'`                      | Regression (output layer)                 |\n",
        "| `'elu'`, `'selu'`, `'softplus'` | Advanced cases                            |\n",
        "\n",
        "Example: Using Different Activation Functions in Keras\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, input_dim=4, activation='tanh'),       # hidden layer with tanh\n",
        "    Dense(8, activation='relu'),                     # hidden layer with relu\n",
        "    Dense(1, activation='sigmoid')                   # output layer for binary classification\n",
        "])\n",
        "```\n",
        "Using Functional API for More Control\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "inputs = Input(shape=(4,))\n",
        "x = Dense(16, activation='relu')(inputs)\n",
        "x = Dense(8, activation='tanh')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "```"
      ],
      "metadata": {
        "id": "mlgYHn3XP8Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q5. How do you add dropout to a neural network model to prevent overfitting ?\n",
        "To add dropout to a neural network in Keras, you use the `Dropout` layer from `tensorflow.keras.layers`. Dropout helps prevent overfitting by randomly \"dropping out\" (setting to zero) a fraction of the input units during training.\n",
        "\n",
        "Step-by-Step: Adding Dropout\n",
        "\n",
        "Import the Layer\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Dropout\n",
        "```\n",
        "Syntax\n",
        "\n",
        "```python\n",
        "Dropout(rate)\n",
        "```\n",
        "\n",
        "* `rate`: fraction of input units to drop (e.g., 0.5 means 50%).\n",
        "\n",
        "---\n",
        "Example: Add Dropout to a Model\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(64,)),   # First hidden layer\n",
        "    Dropout(0.5),                                        # Dropout applied here (50%)\n",
        "    Dense(64, activation='relu'),                        # Second hidden layer\n",
        "    Dropout(0.3),                                        # Dropout applied here (30%)\n",
        "    Dense(1, activation='sigmoid')                       # Output layer\n",
        "])\n",
        "```\n",
        "\n",
        "Why Use Dropout?\n",
        "\n",
        "* Helps prevent overfitting by making the network less reliant on specific neurons.\n",
        "* Forces the network to learn more robust features.\n",
        "* Only active during training, automatically disabled during inference.\n",
        "\n",
        "Notes\n",
        "\n",
        "* Typical values: `0.2` to `0.5`.\n",
        "* Place it **after Dense or Conv layers, not before.\n",
        "* Don’t use it in the **output layer**.\n",
        "\n",
        "---\n",
        "Optional (Functional API version):\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "inputs = Input(shape=(64,))\n",
        "x = Dense(128, activation='relu')(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "```"
      ],
      "metadata": {
        "id": "6KxG5aDFQTpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q6. How do you manually implement forward propagation in a simple neural network?\n",
        "To manually implement forward propagation in a simple neural network, you simulate how data flows from input to output by calculating each layer’s output step-by-step using weights, biases, and activation functions — without using libraries like Keras or PyTorch.\n",
        "What is Forward Propagation?\n",
        "\n",
        "Forward propagation is the process of computing the output of a neural network from given input by applying:\n",
        "\n",
        "1. Weighted sum: $z = w \\cdot x + b$\n",
        "2. Activation: $a = \\text{activation}(z)$\n",
        "Example: One Hidden Layer Neural Network\n",
        "\n",
        "Network Architecture:\n",
        "\n",
        "* Input: 2 neurons\n",
        "* Hidden Layer: 2 neurons, ReLU activation\n",
        "* Output Layer: 1 neuron, Sigmoid activation\n",
        "\n",
        "Step-by-Step Python Code\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Activation functions\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Input (1 sample, 2 features)\n",
        "x = np.array([0.5, 0.8])\n",
        "\n",
        "# Weights and biases\n",
        "# Hidden layer: 2 neurons\n",
        "W1 = np.array([[0.2, 0.4],     # weights from input to hidden neuron 1 and 2\n",
        "               [0.3, 0.7]])\n",
        "b1 = np.array([0.1, 0.2])      # bias for hidden neurons\n",
        "\n",
        "# Output layer: 1 neuron\n",
        "W2 = np.array([0.6, 0.9])      # weights from hidden to output\n",
        "b2 = 0.3                       # bias for output neuron\n",
        "\n",
        "# Forward pass\n",
        "# Step 1: Input to Hidden\n",
        "z1 = np.dot(x, W1) + b1        # shape: (2,)\n",
        "a1 = relu(z1)                  # activation of hidden layer\n",
        "\n",
        "# Step 2: Hidden to Output\n",
        "z2 = np.dot(a1, W2) + b2       # scalar\n",
        "a2 = sigmoid(z2)               # final output\n",
        "\n",
        "# Output\n",
        "print(\"Final Output:\", a2)\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "1. `np.dot(x, W1)` computes input → hidden layer.\n",
        "2. `relu(z1)` applies ReLU activation.\n",
        "3. `np.dot(a1, W2)` computes hidden → output.\n",
        "4. `sigmoid(z2)` gives final prediction between 0 and 1.\n",
        "\n",
        "Output:\n",
        "\n",
        "The final result is a predicted probability (like in binary classification).\n"
      ],
      "metadata": {
        "id": "HVyx-v5xQrd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q7. How do you add batch normalization to a neural network in keras?\n",
        "To add Batch Normalization to a neural network in Keras, you use the `BatchNormalization` layer from `tensorflow.keras.layers`.\n",
        "What is Batch Normalization?\n",
        "\n",
        "Batch Normalization normalizes the inputs of each layer to have:\n",
        "\n",
        "* Mean ≈ 0\n",
        "* Standard deviation ≈ 1\n",
        "\n",
        "This:\n",
        "* peeds up training\n",
        "* Stabilizes learning\n",
        "* Reduces dependence on weight initialization\n",
        "* Can help reduce overfitting\n",
        "\n",
        "How to Use in Keras\n",
        "\n",
        "Import the Layer:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "```\n",
        "Example: Adding Batch Normalization in a Dense Network\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Activation\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(100,)),\n",
        "    BatchNormalization(),           # Add BatchNorm after Dense\n",
        "    Activation('relu'),             # Then apply activation\n",
        "    Dense(32),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer\n",
        "])\n",
        "```\n",
        "\n",
        "---\n",
        "Alternative: Activation inside Dense\n",
        "\n",
        "You can also write:\n",
        "\n",
        "```python\n",
        "model.add(Dense(64, input_shape=(100,)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "```\n",
        "\n",
        "Avoid using `activation='relu'` inside `Dense` if you plan to use BatchNorm after, because:\n",
        "\n",
        "> BatchNorm should be applied before the activation function.\n",
        "\n",
        "Using with Functional API:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Activation\n",
        "\n",
        "inputs = Input(shape=(100,))\n",
        "x = Dense(64)(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dense(32)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "```\n",
        "Tips:\n",
        "* Works well with deep networks\n",
        "* Use with or without Dropout (depends on use case)\n",
        "* Often placed before activation functions (not after)"
      ],
      "metadata": {
        "id": "oyk2cyqCRCYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q8. How can you visualize the training process with accuracy and loss curves?\n",
        " To visualize the training process in Keras with accuracy and loss curves, you can use Matplotlib to plot the values stored in the `History` object returned by `model.fit()`.\n",
        "\n",
        "Step-by-Step: Plot Accuracy & Loss\n",
        "\n",
        "Step 1: Train the Model and Store History\n",
        "\n",
        "```python\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=50,\n",
        "                    batch_size=32)\n",
        "```\n",
        "Step 2: Plot Accuracy and Loss Curves\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy plot\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "What `history.history` Contains:\n",
        "\n",
        "```python\n",
        "print(history.history.keys())\n",
        "```\n",
        "\n",
        "Typical keys:\n",
        "\n",
        "* `'loss'`: training loss\n",
        "* `'val_loss'`: validation loss\n",
        "* `'accuracy'`: training accuracy\n",
        "* `'val_accuracy'`: validation accuracy\n",
        "\n",
        "Tips:\n",
        "\n",
        "* Use `validation_split=0.2` in `fit()` if no separate validation set.\n",
        "* You can add `EarlyStopping` and see when training stopped.\n",
        "* Use `seaborn` for prettier plots (optional)."
      ],
      "metadata": {
        "id": "gsXfRBAORmNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q9. How can you use gradient clipping in keras to control the gradient size and prevent exploding gradients?\n",
        "\n",
        "To use gradient clipping in Keras, you specify clipping options in the optimizer when compiling the model. Gradient clipping helps prevent the exploding gradient problem by capping gradients during backpropagation.\n",
        "\n",
        "Types of Gradient Clipping in Keras:\n",
        "\n",
        "1. Clip by value: Restrict gradient components to a range\n",
        "   `clipvalue=threshold`\n",
        "\n",
        "2. Clip by norm: Restrict the L2 norm of the gradient\n",
        "   `clipnorm=threshold`\n",
        "\n",
        "How to Apply Gradient Clipping\n",
        "\n",
        "Example: Clipping by Norm (Most Common)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)  # clip norm to max 1.0\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "Example: Clipping by Value\n",
        "\n",
        "```python\n",
        "optimizer = Adam(learning_rate=0.001, clipvalue=0.5)  # clip gradients between -0.5 and 0.5\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "When to Use Gradient Clipping?\n",
        "\n",
        "Use it when:\n",
        "\n",
        "* Training deep or recurrent networks\n",
        "* Seeing NaNs or Inf in training\n",
        "* Experiencing instability in early epochs\n",
        "\n",
        "Best Practices:\n",
        "\n",
        "| Type        | Use When...                                        |\n",
        "| ----------- | -------------------------------------------------- |\n",
        "| `clipnorm`  | You want to cap the overall gradient magnitude     |\n",
        "| `clipvalue` | You want to cap individual gradient values         |"
      ],
      "metadata": {
        "id": "49oNtfGpR88E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q10. How can you create a customer loss function in keras?\n",
        "To create a custom loss function in Keras, you define a Python function that takes the true labels (`y_true`) and the predicted labels (`y_pred`) as inputs and returns a scalar loss value.\n",
        "\n",
        "You can then pass this function to the `loss` parameter in `model.compile()`.\n",
        "Step-by-Step: Custom Loss Function in Keras\n",
        "\n",
        "Basic Format:\n",
        "\n",
        "```python\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # compute loss\n",
        "    return loss_value\n",
        "```\n",
        "\n",
        "* `y_true` and `y_pred` are tensors.\n",
        "* Use TensorFlow operations (not NumPy).\n",
        "\n",
        "Example 1: Mean Squared Error (custom version)\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_mse(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "```\n",
        "\n",
        "Use it in model:\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam', loss=custom_mse, metrics=['mae'])\n",
        "```\n",
        "Example 2: Weighted Binary Crossentropy\n",
        "\n",
        "```python\n",
        "def weighted_binary_crossentropy(y_true, y_pred):\n",
        "    weight = 2.0  # apply higher penalty to positive class\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    return tf.reduce_mean(weight * y_true * bce + (1 - y_true) * bce)\n",
        "```\n",
        "Example 3: Huber Loss (smooth for outliers)\n",
        "\n",
        "```python\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small = tf.abs(error) <= delta\n",
        "    squared_loss = 0.5 * tf.square(error)\n",
        "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
        "    return tf.where(is_small, squared_loss, linear_loss)\n",
        "```\n",
        "Using Custom Loss with Additional Arguments\n",
        "\n",
        "If your loss function requires extra arguments (e.g., weight, delta), wrap it using a function:\n",
        "\n",
        "```python\n",
        "def make_custom_loss(weight):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        return tf.reduce_mean(weight * tf.square(y_true - y_pred))\n",
        "    return loss_fn\n",
        "\n",
        "# Compile with it\n",
        "model.compile(optimizer='adam', loss=make_custom_loss(1.5))\n",
        "```"
      ],
      "metadata": {
        "id": "YqN-bzHASXVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q11. How can you visualize the structure of a neural network model in keras?\n",
        "To visualize the structure of a neural network model in Keras, you can use tools like:\n",
        "\n",
        "1. `model.summary()` (Text-based View)\n",
        "\n",
        "```python\n",
        "model.summary()\n",
        "```\n",
        "* Displays a layer-wise table: layer names, output shapes, and parameter counts.\n",
        "* Best for quick overview in code or console.\n",
        "\n",
        "2. `plot_model()` from `tensorflow.keras.utils`\n",
        "\n",
        "This gives you a diagram view of the model.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "```\n",
        "\n",
        "* `to_file`: Saves the model architecture as an image file (e.g. `model.png`)\n",
        "* `show_shapes=True`: Displays input/output shape per layer\n",
        "* `show_layer_names=True`: Shows layer names (enabled by default)\n",
        "\n",
        "Output: A graphical diagram of the model (saved image)\n",
        "\n",
        "3. Visualize with **TensorBoard** (Advanced & Interactive)\n",
        "\n",
        "If you're using the Functional API or a complex model:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
        "model.fit(X_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n",
        "```\n",
        "\n",
        "Then in terminal:\n",
        "\n",
        "```bash\n",
        "tensorboard --logdir=./logs\n",
        "```\n",
        "\n",
        "Open browser at `http://localhost:6006` → See model graph and metrics.\n",
        "Pro Tip: For Functional or Subclassed Models\n",
        "\n",
        "If using `Functional API`, diagrams will show branches, skip connections, etc.\n",
        "Summary Table:\n",
        "\n",
        "| Method            | Output         | Best For                        |\n",
        "| ----------------- | -------------- | ------------------------------- |\n",
        "| `model.summary()` | Text           | Console view of architecture    |\n",
        "| `plot_model()`    | Image (.png)   | Static diagram for reports/docs |\n",
        "| TensorBoard       | Interactive UI | Debugging + detailed graph view |\n"
      ],
      "metadata": {
        "id": "X4f9eY3TSrd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}